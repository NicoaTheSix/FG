{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79bf2a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
      "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
      "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
      "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n",
      "c:\\Users\\nick5\\anaconda3\\envs\\FG\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAGA exists: True\n",
      "SAGA所有有的檔案以及其對應路徑\n",
      "pathSAGAM1:D:\\dataset\\SAGA\\Composite APT Campaigns Dataset\\M1.json\n",
      "pathSAGAM10:D:\\dataset\\SAGA\\Composite APT Campaigns Dataset\\M10.json\n",
      "pathSAGAM2:D:\\dataset\\SAGA\\Composite APT Campaigns Dataset\\M2.json\n",
      "pathSAGAM3:D:\\dataset\\SAGA\\Composite APT Campaigns Dataset\\M3.json\n",
      "pathSAGAM4:D:\\dataset\\SAGA\\Composite APT Campaigns Dataset\\M4.json\n",
      "pathSAGAM5:D:\\dataset\\SAGA\\Composite APT Campaigns Dataset\\M5.json\n",
      "pathSAGAM6:D:\\dataset\\SAGA\\Composite APT Campaigns Dataset\\M6.json\n",
      "pathSAGAM7:D:\\dataset\\SAGA\\Composite APT Campaigns Dataset\\M7.json\n",
      "pathSAGAM8:D:\\dataset\\SAGA\\Composite APT Campaigns Dataset\\M8.json\n",
      "pathSAGAM9:D:\\dataset\\SAGA\\Composite APT Campaigns Dataset\\M9.json\n",
      "pathSAGAG1:D:\\dataset\\SAGA\\Generated APT Campaigns Dataset\\G1.json\n",
      "pathSAGAG10:D:\\dataset\\SAGA\\Generated APT Campaigns Dataset\\G10.json\n",
      "pathSAGAG11:D:\\dataset\\SAGA\\Generated APT Campaigns Dataset\\G11.json\n",
      "pathSAGAG12:D:\\dataset\\SAGA\\Generated APT Campaigns Dataset\\G12.json\n",
      "pathSAGAG13:D:\\dataset\\SAGA\\Generated APT Campaigns Dataset\\G13.json\n",
      "pathSAGAG14:D:\\dataset\\SAGA\\Generated APT Campaigns Dataset\\G14.json\n",
      "pathSAGAG15:D:\\dataset\\SAGA\\Generated APT Campaigns Dataset\\G15.json\n",
      "pathSAGAG16:D:\\dataset\\SAGA\\Generated APT Campaigns Dataset\\G16.json\n",
      "pathSAGAG17:D:\\dataset\\SAGA\\Generated APT Campaigns Dataset\\G17.json\n",
      "pathSAGAG18:D:\\dataset\\SAGA\\Generated APT Campaigns Dataset\\G18.json\n",
      "pathSAGAG19:D:\\dataset\\SAGA\\Generated APT Campaigns Dataset\\G19.json\n",
      "pathSAGAG2:D:\\dataset\\SAGA\\Generated APT Campaigns Dataset\\G2.json\n",
      "pathSAGAG20:D:\\dataset\\SAGA\\Generated APT Campaigns Dataset\\G20.json\n",
      "pathSAGAG3:D:\\dataset\\SAGA\\Generated APT Campaigns Dataset\\G3.json\n",
      "pathSAGAG4:D:\\dataset\\SAGA\\Generated APT Campaigns Dataset\\G4.json\n",
      "pathSAGAG5:D:\\dataset\\SAGA\\Generated APT Campaigns Dataset\\G5.json\n",
      "pathSAGAG6:D:\\dataset\\SAGA\\Generated APT Campaigns Dataset\\G6.json\n",
      "pathSAGAG7:D:\\dataset\\SAGA\\Generated APT Campaigns Dataset\\G7.json\n",
      "pathSAGAG8:D:\\dataset\\SAGA\\Generated APT Campaigns Dataset\\G8.json\n",
      "pathSAGAG9:D:\\dataset\\SAGA\\Generated APT Campaigns Dataset\\G9.json\n",
      "pathSAGAC1:D:\\dataset\\SAGA\\Known APT Campaigns Dataset\\C1.json\n",
      "pathSAGAC2:D:\\dataset\\SAGA\\Known APT Campaigns Dataset\\C2.json\n",
      "pathSAGAC3:D:\\dataset\\SAGA\\Known APT Campaigns Dataset\\C3.json\n",
      "pathSAGAC4:D:\\dataset\\SAGA\\Known APT Campaigns Dataset\\C4.json\n",
      "pathSAGAC5:D:\\dataset\\SAGA\\Known APT Campaigns Dataset\\C5.json\n",
      "pathSAGAC6:D:\\dataset\\SAGA\\Known APT Campaigns Dataset\\C6.json\n",
      "pathSAGAC7:D:\\dataset\\SAGA\\Known APT Campaigns Dataset\\C7.json\n",
      "pathSAGAC8:D:\\dataset\\SAGA\\Known APT Campaigns Dataset\\C8.json\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import gym\n",
    "import time\n",
    "import umap\n",
    "import json\n",
    "import shlex\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.manifold import TSNE\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.signal import savgol_filter\n",
    "from gym import spaces\n",
    "from collections import deque\n",
    "\n",
    "# =========================\n",
    "# Path settings\n",
    "# =========================\n",
    "pathSAGA = os.path.join(\"D:\\\\\", \"dataset\", \"SAGA\")\n",
    "pathCasinoLimit = os.path.join(\"D:\\\\\", \"dataset\", \"CasinoLimit\")\n",
    "pathOutput=os.path.join(pathSAGA,\"result\")\n",
    "pathSAGAmalicious=os.path.join(pathSAGA,\"SAGA_malicious.json\")\n",
    "print(\"SAGA exists:\", os.path.exists(pathSAGA))\n",
    "\n",
    "listSAGAFiles=[]\n",
    "for dirAPTCampaign in os.listdir(pathSAGA):\n",
    "    pathAPTCampaign=os.path.join(pathSAGA,dirAPTCampaign)\n",
    "    if os.path.isdir(pathAPTCampaign) and dirAPTCampaign != \"result\":\n",
    "        for auditLog in os.listdir(pathAPTCampaign):\n",
    "            pathAuditLog=os.path.join(pathAPTCampaign,auditLog)\n",
    "            #print(\"current processing:\",pathAuditLog)\n",
    "            #print(auditLog)\n",
    "            if os.path.isfile(pathAuditLog):\n",
    "                listSAGAFiles.append(\"path\"+\"SAGA\"+auditLog.split(\".\")[0])\n",
    "                globals()[\"path\"+\"SAGA\"+auditLog.split(\".\")[0]]=pathAuditLog\n",
    "print(\"SAGA所有有的檔案以及其對應路徑\")\n",
    "for i in listSAGAFiles:\n",
    "    print(i+\":\"+globals()[i])\n",
    "\n",
    "\n",
    "def loadSagaJson(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "        l = []\n",
    "        for i in file:\n",
    "           l.append(json.loads(i)) \n",
    "    return l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acbdd880",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadSagaJson(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "        l = []\n",
    "        for i in file:\n",
    "           l.append(json.loads(i)) \n",
    "    return l\n",
    "def sigmoid(x):\n",
    "    #這邊做了一個避免數字跑出特定範圍的東西\n",
    "    #這邊承襲原本的版本 如果順利之後可以考慮用原版的去跑跑看\n",
    "    x =np.clip(x,-500,5.0)\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def softmax(x, temperature=1.0):\n",
    "    #同上 先用用看別人的順利再跑跑看不做限制的\n",
    "    x = np.clip(x, -500, 500)\n",
    "    x_max = np.max(x)\n",
    "    exp_x = np.exp((x - x_max) / temperature)\n",
    "    sum_exp_x = np.sum(exp_x)\n",
    "    if sum_exp_x == 0:\n",
    "        return np.ones_like(x) / len(x)\n",
    "    return exp_x / sum_exp_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b520c266",
   "metadata": {},
   "source": [
    "## RL\n",
    "這邊設定的類別有兩種，一是「環境」、二是「模型」(或是RL的演算法)\n",
    "環境取決的載入哪一種紀錄檔案、資料集。如網路封包日誌就會看日誌用甚麼協定、一次傳輸多少bits等訊息，而Audit Log(審計日誌)則會看說使用哪個服務和做了什麼動作。\n",
    "RL模型則是看要套用哪種演算法和技術\n",
    "#### 環境設置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "463befc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AuditLogEnv(gym.Env):\n",
    "    def __init__(self,logFile=\"G16.json\"):\n",
    "        # 初始化環境\n",
    "        ## 基礎設定\n",
    "        self.logFile=logFile\n",
    "        #logguardQ有設置size但很明顯我要處理的檔案大很多因此不考慮\n",
    "        self.stateDim=100 #代表傳入的狀態Dimension有100維\n",
    "        self.actionDim=4 #代表有四種動作\n",
    "        ## 接著是載入某份log(這邊預設維G16.json，因為它檔案很小)\n",
    "        self.logs=self.loadLogs(logFile)#這邊載入會使用 \n",
    "        if len(self.logs) == 0:#沒有成功載入任何 AuditLog的話會出現錯誤\n",
    "            raise ValueError(f\"No valid log entries found in {logFile}.\")\n",
    "        self.attackPattern=[]#這邊logguardQ給了一個輸入維度在哪種情況下可能是攻擊，但我這邊還不確定怎麼做\n",
    "        self.noiseLvl=0.05 # 一個加入可能的躁點大概佔幾趴 不確定會不會用到\n",
    "        ## 以下是代理每次動作後看做了哪些事可能會更新某些值\n",
    "        self.ipCounts={} # 由於AuditLog也有ip相關可能會用到\n",
    "        self.logIndex=0 # 看到第幾條\n",
    "        self.stepCount=0 # 現在走了幾步 \n",
    "        self.anomalyCount=0\n",
    "        self.visitedStates=set() # 走訪過那些狀態\n",
    "        self.processedLogs=set()# 已經處理了哪些東西 作用域: 單次回合 (Single Episode)\n",
    "        self.processedLogsGlobal=set() #作用域: 整個環境的生命週期 (Entire Lifetime)。\n",
    "        self.featureRanges={}# 把記錄到的某些數值縮放到某個數字區間 為了提高訓練效率和穩定性。 不確定會不會用到\n",
    "        # 權重本身可以寫死也可以靠模型自己調整，但我直接拿掉整個權重的設計\n",
    "        # 主要是我也沒有設備可以弄到自己調整\n",
    "        #self.featureWeights={}# input的每個東西的權重，不確定要怎麼分配但先放著\n",
    "        \n",
    "        ## 常見弱點出現在哪些東西上\n",
    "        vulnName=[]#常見的有問題的AuditLog可能的特徵 但這邊什麼都沒放 才剛架起來\n",
    "        attackParamsValues=[]#logGuardQ使用常見的 XSS攻擊會出現的字串特徵 跟上面很像\n",
    "        attackRegEx=[]# 仿造上面 這邊則用RegEx做做看 一樣還沒放入任何東西\n",
    "        # 接下來是先載入一次這次回合的(Episode)的AuditLog 並且檢查有多少是非benign\n",
    "        ## 它的主要功能是在環境載入完所有日誌後，對這些日誌進行初步的分析和統計，以瞭解數據集中異常日誌的「真實分佈」\n",
    "        ###這邊我還沒改好\n",
    "        for _, logEntry in self.logs.iterrows():\n",
    "            if self.isAnomaly(logEntry):\n",
    "                self.anomalyCount += 1\n",
    "        print(f\"Loaded {len(self.logs)} valid log entries from {logFile}.\")\n",
    "        print(f\"Anomaly distribution: {self.anomalyCount}/{len(self.logs)} ({self.anomalyCount/len(self.logs)*100:.1f}% anomalies)\")\n",
    "        self.reset()\n",
    "    def loadLogs(self,logFile,dataset:str=\"SAGA\"):\n",
    "        #預設載入SAGA資料集\n",
    "        #這邊是載入AuditLog的地方，要做成pandas.DataFrame\n",
    "        listColumns=['relation','timestamp','label','srcNode.UUID','srcNode.Name','srcNode.Image','srcNode.Cmdline','srcNode.Type','srcNode.Pid','dstNode.UUID','dstNode.Key','dstNode.Type','dstNode.Value','dstNode.Name','dstNode.Srcaddress','dstNode.Dstaddress','dstNode.Port','dstNode.Image','dstNode.Cmdline','dstNode.Pid','dstNode','dstNode.Path']#有甚麼樣的欄位取決於現在讀哪一個資料集\n",
    "        listLogs=[]\n",
    "        #讀取檔案\n",
    "        try:\n",
    "            with open(logFile,\"r\",encoding='utf-8')as file:\n",
    "                for line in file:\n",
    "                    listLogs.append(json.loads(line))\n",
    "                    \"\"\"\n",
    "                    這邊先沒有用到但先不刪除\n",
    "                    if lens(part) >=1:\n",
    "                        listLogs.append(listParts[:11])\n",
    "                    else:\n",
    "                        print(f\"skipping malformed line:{line.strip()},except 11 fields,got{len(listParts)}\")\n",
    "                        \"\"\"\n",
    "            pd.json_normalize(listLogs)\n",
    "            if not listLogs:\n",
    "                print(f\"Warning:no valid log entries found in {logFile}.\")\n",
    "        except FileNotFoundError:\n",
    "            raise FileNotFoundError(f\"File {logFile} not found.\")\n",
    "        except Exception as e:\n",
    "            raise Exception({f\"Error loading file {logFile}: {str(e)}\"})\n",
    "        # 轉換成DataFrame\n",
    "        df=pd.DataFrame(listLogs,columns=listColumns)\n",
    "        # 下面則是要把某些部分有固定種類的東西轉換成數值表示\n",
    "        # 舉例df['status_code'] = pd.to_numeric(df['status_code'], errors='coerce')\n",
    "        # 特徵擷取分為四種\n",
    "        #   無大小關係的一組數字(舉例：IP)：計算出現頻率 或 映射到不同數字上\n",
    "        #   有大小關係的數字(舉例：傳送檔案或字串的大小)：進行歸一化處理(縮放到特定區間)\n",
    "        #   字串：比對是否與可疑字串有關\n",
    "        df['relation'] = pd.to_numeric(df['relation'], errors='coerce')\n",
    "        return df\n",
    "    def isAnomaly(self,logEntry):\n",
    "        #對答案\n",
    "        #這邊logguardQ的實作方法是給了一些很刻意的線索然後比對線索\n",
    "        #我的實作方式是直接看標籤是不是benign\n",
    "        #當然我會希望可以做得更好但先這樣\n",
    "        return lambda logEntry: logEntry.get('label') != \"benign\"\n",
    "    def extractFeature(self,logEntry):\n",
    "        #1 擷取logEntry的各項Value存到各個變數\n",
    "        #2 特徵標準化以及加權\n",
    "        #3 特徵向量組合(將所有特徵封裝組合成一個numpy陣列)\n",
    "        features=np.array([])\n",
    "        normalizedFeatures=np.zeros(features)\n",
    "        for i,key in enumerate([0,0,0,00]):\n",
    "            #最後再將所有特徵再次縮放到0,1之間\n",
    "            minVal,maxVal=self.featureRanges(key)\n",
    "            normalizedFeatures[i]=np.clip((features[i]-minVal)/(maxVal-minVal+1e-10),0,1)\n",
    "        return normalizedFeatures\n",
    "    def reset(self):\n",
    "        #1 重製游標/指標\n",
    "        self.stepCount-0\n",
    "        #2 清空歷史決策紀錄\n",
    "        self.processedLogs=set()\n",
    "        #3 初始化統計用變數\n",
    "        #4 隨機選一段要跑的Audit log\n",
    "        #5 回傳初始的State\n",
    "        self.stepCount=0\n",
    "        self.processedLogs=set()\n",
    "        if len(self.logs) > 0:\n",
    "            unprocessedIndices=[i for i in range(len(self.logs))if i not in self.processedLogsGlobal]\n",
    "            if unprocessedIndices:\n",
    "                self.logIndex=random.choice(unprocessedIndices)\n",
    "            else:\n",
    "                self.logIndex=np.random.randint(0,len(self.logs))\n",
    "        else:\n",
    "            raise IndexError(f\"Log Index{self.logIndex} out of range [0,{len(self.logs)}]\")\n",
    "        self.ipCounts={}\n",
    "        self.visitedStates=set()\n",
    "        self.state=self.getState()\n",
    "        return self.state\n",
    "    def getState(self):\n",
    "        if 0 <= self.logIndex < len(self.logs):\n",
    "            logEntry=self.logs.iloc[self.logIndex]\n",
    "            # ip\n",
    "            ip=logEntry.get(\"ip\")\n",
    "            if ip:self.ipCounts[ip]=self.ipCounts.gets(ip,0)+1\n",
    "            if len(self.ipCounts)>100:\n",
    "                ipOldest=list(self.ipCounts.keys())[0]\n",
    "                self.ipCounts[ipOldest]-=1\n",
    "                if self.ipCounts[ipOldest]==0:\n",
    "                    del self.ipCounts[ipOldest]\n",
    "            state=self.extractFeature(logEntry)\n",
    "            self.visitedStates.add(tuple(state))\n",
    "        else:\n",
    "            raise IndexError(f\"Log Index {self.logIndex} out of range [0,{len(self.logs)}]\")\n",
    "        return\n",
    "    def  updateNoise(self):\n",
    "        self.noiseLvl=0.05\n",
    "    def step(self,action):\n",
    "        # 一步\n",
    "        self.stepCount+=1\n",
    "        if 0<=self.logIndex <len(self.logs):\n",
    "            logEntry=self.logs.iloc[self.logIndex]\n",
    "            isAnomaly=self.isAnomaly(logEntry)\n",
    "            if action == 0 and isAnomaly:\n",
    "                score = 25.0\n",
    "                done = False\n",
    "            elif action == 0 and not isAnomaly:\n",
    "                score = -15.0\n",
    "                done = False\n",
    "            elif action != 0 and isAnomaly:\n",
    "                score = 2.0\n",
    "                done = False\n",
    "            if np.random.rand() <self.noiseLvl:\n",
    "                score -= 0.5\n",
    "            self.processedLogs.add(self.logIndex)\n",
    "            self.logIndex = (self.logIndex + 1) % len(self.logs)\n",
    "            self.state=self.getState()\n",
    "            done = self.stepCount>=5 or len(self.processedLogsGlobal)>= self.anomalyCount4\n",
    "            return self.state,score,done,isAnomaly\n",
    "        else:\n",
    "            raise IndexError(f\"Log Index {self.logIndex} out of range [0,{len(self.logs)}]\")\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f87f92",
   "metadata": {},
   "source": [
    "#### 決策機設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48166e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DQN的運作流程\n",
    "迴圈\n",
    "    1.環境重製\n",
    "    2.根據現在狀態選擇一個動作\n",
    "    3.透過動作與環境運作之後\n",
    "    4.根據這次互動之後更新權重\n",
    "\n",
    "\"\"\"\n",
    "class DQN:\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self,stateDim,actionDim,hiddenDim=16):\n",
    "        ##同步狀態維度(狀態特徵數量)和動作維度\n",
    "        self.stateDim=stateDim\n",
    "        self.actionDim=actionDim\n",
    "        ##  設定深度學習的網路層數以及參數數量\n",
    "        self.hiddenDim=16\n",
    "        self.weightS1=np.random.randn(stateDim,hiddenDim)*0.01\n",
    "        self.weightS2=np.random.randn(hiddenDim,actionDim)*0.01\n",
    "        self.memory= deque(maxlen=1000)\n",
    "        ##  各項演算法中的代數設定\n",
    "        self.gamma =0.99 #折扣因子\n",
    "        self.epsilon=1.0#  ε-greedy的 ε值 判斷模型該「探索」還是「利用知識」\n",
    "        self.epsilonMin=0.01# ε的最小值\n",
    "        self.epsilonDecay=0.998#  ε-greedy的衰減值 模型會逐漸從「探索」轉向利用知識\n",
    "        self.learnRate=0.002# 學習率\n",
    "        self.varianceHistory=[]# 紀錄每個回合(episode) 代理所獲得分數的標準差\n",
    "        self.scoreStates=[]#用於儲存分數的平均值和標準差\n",
    "        self.episode=0\n",
    "        self.actionHistory=[]\n",
    "        \n",
    "    def chooseAction(self,state,visitedStates):\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            action = np.random.choice(self.actionDim)\n",
    "        else:\n",
    "            qValues=self.forward(state)\n",
    "            action =np.argmax(qValues)\n",
    "        curiosityBonus=1.0 if tuple(state) not in visitedStates else 0.0\n",
    "        ## 如果採取一個新動作的時候會觸發一個好奇心獎勵值\n",
    "        self.actionHistory.append(action)\n",
    "        return action,curiosityBonus\n",
    "    def forward(self,state):\n",
    "        #用矩陣乘法把狀態乘上第一層權重再用sigmoid(隱藏層的活化函數)\n",
    "        hidden = sigmoid(np.dot(state,self.weightS1))\n",
    "        #再來矩陣乘法乘上第二層權重\n",
    "        #向量中的每一個值就是神經網路預測的在當狀態下採取特定動作的Q值\n",
    "        return np.dot(hidden,self.weightS2)\n",
    "    def updateWeights(self,state,action,reward,prevState,curiosityBonus):\n",
    "        nextQValue=self.forward(state)\n",
    "        target=reward+self.gamma*np.max(nextQValue)+curiosityBonus\n",
    "        currentQ=self.forward(prevState)[action]\n",
    "        delta=target-currentQ\n",
    "        hidden=sigmoid(np.dot(prevState,self.weightS1))\n",
    "        deltaOutput=np.zeros(self.actionDim)\n",
    "        deltaOutput[action]=delta\n",
    "        grade2=np.outer(prevState,deltaOutput)\n",
    "        deltaHidden=np.dot(self.weightS2,deltaOutput)*hidden*(1-hidden)\n",
    "        grade1=np.outer(prevState,deltaHidden)\n",
    "        self.weightS1+=self.learnRate*grade1\n",
    "        self.weightS2+=self.learnRate*grade2\n",
    "        self.memory.append((prevState,action,reward,state))\n",
    "        self.epsilon=max(self.epsilonMin,self.epsilon*self.epsilonDecay)\n",
    "        self.scoreStates['std']=np.sqrt(self.scoreStates.get('std',0)**2*0.99+(reward-self.scoreStates['mean'])**2*0.01)\n",
    "        self.varianceHistory.append(self.scoreStates['std'])\n",
    "    def reportDetection():\n",
    "        #這個不知道在幹嘛的\n",
    "        pass\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "class PPO:\n",
    "    def __init__(self):\n",
    "        return\n",
    "    def chooseAction():\n",
    "        return\n",
    "    def forward():\n",
    "        return\n",
    "    def updateWeights():\n",
    "        return\n",
    "    def reportDetection():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b7742c",
   "metadata": {},
   "source": [
    "#### 功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02672e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateStatisticalSignificance():\n",
    "    #針對不同的RL模型進行更嚴謹的性能和統計學比較\n",
    "    #實作與功能\n",
    "    # 先為每個模型的得分計算平均數 中位數 標準差 常態分佈檢定\n",
    "    # 再來選擇並且統計檢定 比較每兩個東西模型的表現\n",
    "    # 最後印出剩下的結果\n",
    "    return\n",
    "def runSimulation(model,env,modelName,episodes,maxSteps):\n",
    "    #1 初始化變數\n",
    "    scores=[]\n",
    "    f1Scores=[]\n",
    "    stepToDetection=[]\n",
    "    detections=0\n",
    "    truePositives=0\n",
    "    falsePositives=0\n",
    "    trueNegatives=0\n",
    "    falseNegatives=0\n",
    "    totalAnomalies=0\n",
    "    totalStart=time.time()\n",
    "    cumulativeTp=[]\n",
    "    #2 迴圈\n",
    "    for episode in range(episodes):\n",
    "        #2.1 提前停止條件\n",
    "        if len(env.processedLogsGlobal)>= env.anomalyCount:\n",
    "            #如果已經跑完全部的異常的話即停止\n",
    "            print(f\"{modelName} stopped early at episode {episode}: All {env.anomalyCount} anomalies processed.\")\n",
    "            break\n",
    "        #每個episode開始 重置環境 清空episode統計\n",
    "        state = env.reset()\n",
    "        totalScore = 0\n",
    "        steps=  0\n",
    "        done = False\n",
    "        episodeTruePositive=0\n",
    "        episodeAnomalies=0\n",
    "        actionCounts=np.zeros(4)\n",
    "        #每一百步會更新一次躁點避免死記硬背\n",
    "        if episode % 100 ==0:\n",
    "            env.updateNoise()\n",
    "        #確認model有 episode\n",
    "        if hasattr(model,\"episode\"):\n",
    "            model.episode=episode\n",
    "        #   model與環境互動\n",
    "        while not done and steps < maxSteps:\n",
    "            prevState=state#記住前一個state\n",
    "            #選擇動作(choosing action)\n",
    "            action,curiosityBonus-model.chooseAction(state,env.visitedState)\n",
    "            actionCounts[action]+=1\n",
    "            #取出當前的log並且判斷是否是anomaly\n",
    "            logEntry=env.logs.iloc[env.logIndex]\n",
    "            isAnomaly-env.isAnomaly(logEntry)\n",
    "            if isAnomaly and env.logIndex not in env.processedLogsGlobal:\n",
    "                episodeAnomalies+=1\n",
    "                totalAnomalies+=1\n",
    "                env.processedLogsGlobal.add(env.logIndex)\n",
    "            nextState,score,done,isAnomalyStep=env.step(action)\n",
    "            #執行動作\n",
    "            if action == 0 and isAnomaly:\n",
    "                episodeTruePositives+=1\n",
    "                truePositives+=1\n",
    "            elif action == 0 and not isAnomaly:\n",
    "                falsePositives+=1\n",
    "            elif action !- 0 and isAnomaly:\n",
    "                falseNegatives+=1\n",
    "            elif action !- 0 not isAnomaly:\n",
    "                trueNegatives+=1\n",
    "            #更新權重\n",
    "            model.updateWeight(nextState,action,score,prevState,curiosityBonus)\n",
    "            model.reportDetection(isAnomalyStep,action)\n",
    "            #更新狀態\n",
    "            state = nextState\n",
    "            totalScore += score\n",
    "            step += 1\n",
    "        #分類成功就加一\n",
    "        if episodeTruePositives > 0:\n",
    "            detection+=1\n",
    "        #計算回合分數\n",
    "        scores.append(totalScore)\n",
    "        precision = episodeTruePositives / (episodeTruePositives+falsePositives)if (episodeTruePositives+falsePositives)>0 else 0\n",
    "        recall = episodeTruePositives/(episodeTruePositives+falseNegatives)if (episodeTruePositives+falseNegatives)>0 else 0\n",
    "        f1 = 2 * (precision*recall)/(precision+recall) if (precision+recall)>0 else 0\n",
    "        #更新該回合累積\n",
    "        f1Scores.append(f1)\n",
    "        stepsToDetection.append(steps)\n",
    "        cumulativeTp.append(truePositives)\n",
    "        if episode % 500 == 0 or episode == episodes -1 or len(env.processedLogsGlobal)>-env.anomalyCount:\n",
    "            precision = truePositives / ( truePositives+falsePositives) if (truePositives+falsePositives) > 0 else 0\n",
    "            recall - truePositives / (truePositives+ falseNegatives)if (truePositives+trueNegatives) >0 else 0\n",
    "            f1Score = 2 * (precision*recall)/(precision+ recall)if (precision+recall) > 0 else 0\n",
    "            print(f\"\"\"\n",
    "                  {modelName} Episode {episode}: Detection {detections}/{episode+1}({detection/(episode+1)*100:.1f}\")\n",
    "                  True Positives: {truePositives}, False Positives: {falsePositives}\n",
    "                  True Negative: {trueNegatives}, False Negatives: {falseNegatives}\n",
    "                  Total Anomalies Encounter:{totalAnomalies} (Episode Anomalies: {episodeAnomalies})\n",
    "                  Global Processed Logs: {len(env.processedLogsGlobal)}\n",
    "                  Precision: {precision:.4f},Recall: {recall:.4f},F1-score: {f1Score:4f}\n",
    "                  Action Distribution: {actionCounts /actionCounts.sum()}\n",
    "                  \"\"\")\n",
    "        #計算運算時間\n",
    "        totalTime= time.time()- totalTime\n",
    "    return {\"scores\":scores,\"f1Scores\":f1Scores,\"stepsToDetection\":stepToDetection,\"detections\":detections,\"truePositives\":truePositives,\"falsePositive\":falsePositives,\"falseNegatives\":falseNegatives,\"totalAnomalies\":totalAnomalies,\"cumulativesTp\":cumulativeTp,\"actionHistory\":model.actionHistory}\n",
    "def displayResult(model=\"\",dictResult:dict={}):\n",
    "    precision=dictResult['tp']/(dictResult['tp']+dictResult['fp'])\n",
    "    recall=dictResult['tp']/(dictResult['tp']+dictResult['fn'])\n",
    "    f1Score=2*(precision*recall)/(precision+recall)\n",
    "    successfulSteps=[s for s in dictResult['steps'][-100:]if s<5]\n",
    "    subTitle=f\"\"\"\n",
    "{model} Final Result\n",
    "=====================\n",
    "precision:{precision}\n",
    "recall:{recall}\n",
    "detection:{dictResult['detection']/len(dictResult['scores'])}({dictResult['detection']}/\n",
    "{len(dictResult['scores'])*100:.1f}%)\n",
    "true positive:{dictResult['tp']}\n",
    "false positive:{dictResult['fp']}\n",
    "true negative:{dictResult['tn']}\n",
    "false negative:{dictResult['fn']}\n",
    "total anomalies encountered:{dictResult['anomalies']}\n",
    "({dictResult['anomalies']/dictResult['tp']+dictResult['tn']+dictResult['fp']+dictResult['fn']*100:.1f}% of steps)\n",
    "Mean Reward (all episodes): {np.mean(dictResult['scores']):.4f} ± {np.std(dictResult['scores']):.4f}\n",
    "Mean F1-Score (all episodes): {np.mean(f1Score):.4f} ± {np.std(f1Score):.4f}\n",
    "Mean Steps per episode (all episodes): {np.mean(dictResult['steps']):.1f} ± {np.std(dictResult['steps']):.1f}\n",
    "Metrics for last 100 Episodes:\n",
    "Mean Reward (last 100): {np.mean(dictResult['scores'][-100:]):.4f} ± {np.std(dictResult['scores'][-100:]):.4f}\n",
    "Mean F1-Scores (last 100): {np.mean(f1Score[-100:]):.4f} ± {np.std(f1Score[-100:]):.4f}\n",
    "Steps to Detection (last 100, successful episodes): {np.mean(successfulSteps):.1f} ± {np.std(successfulSteps):.1f}\n",
    "\"\"\"if successfulSteps else \"No Successful episodes\"\n",
    "    print(subTitle)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4be507",
   "metadata": {},
   "source": [
    "# 主程式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b42e407e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 694858 valid log entries from D:\\dataset\\SAGA\\Composite APT Campaigns Dataset\\M1.json.\n",
      "Anomaly distribution: 694858/694858 (100.0% anomalies)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'dict' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#環境設定初始化\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m env\u001b[38;5;241m=\u001b[39m\u001b[43mAuditLogEnv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogFile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlistSAGAFiles\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m#RL模型初始化\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m#回合(Episode)設定初始化\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m \n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m#印出結果\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[31], line 38\u001b[0m, in \u001b[0;36mAuditLogEnv.__init__\u001b[1;34m(self, logFile)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m valid log entries from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlogFile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnomaly distribution: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39manomalyCount\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39manomalyCount\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogs)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m% anomalies)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[31], line 110\u001b[0m, in \u001b[0;36mAuditLogEnv.reset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mipCounts\u001b[38;5;241m=\u001b[39m{}\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvisitedStates\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m--> 110\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetState\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\n",
      "Cell \u001b[1;32mIn[31], line 123\u001b[0m, in \u001b[0;36mAuditLogEnv.getState\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mipCounts[ipOldest]\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    122\u001b[0m             \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mipCounts[ipOldest]\n\u001b[1;32m--> 123\u001b[0m     state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextractFeature\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogEntry\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvisitedStates\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mtuple\u001b[39m(state))\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[31], line 87\u001b[0m, in \u001b[0;36mAuditLogEnv.extractFeature\u001b[1;34m(self, logEntry)\u001b[0m\n\u001b[0;32m     84\u001b[0m normalizedFeatures\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mzeros(features)\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m([\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m00\u001b[39m]):\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;66;03m#最後再將所有特徵再次縮放到0,1之間\u001b[39;00m\n\u001b[1;32m---> 87\u001b[0m     minVal,maxVal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatureRanges\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     88\u001b[0m     normalizedFeatures[i]\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mclip((features[i]\u001b[38;5;241m-\u001b[39mminVal)\u001b[38;5;241m/\u001b[39m(maxVal\u001b[38;5;241m-\u001b[39mminVal\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1e-10\u001b[39m),\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatureWeights[key]\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m normalizedFeatures\n",
      "\u001b[1;31mTypeError\u001b[0m: 'dict' object is not callable"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\" :\n",
    "    #先印出某個Audit Log檔案的前十行\n",
    "    \"\"\"\n",
    "    \n",
    "    fileNameM1=listSAGAFiles[0].split(\"th\")[1]\n",
    "    print(f\"Preview the first 10 lines in file{fileNameM1}\")\n",
    "    listLogsM1=loadSagaJson(globals()[listSAGAFiles[0]])\n",
    "    for i in range(10):\n",
    "        print(listLogsM1[i])\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    #環境設定初始化\n",
    "    env=AuditLogEnv(logFile=globals()[listSAGAFiles[0]])\n",
    "    #RL模型初始化\n",
    "    \n",
    "    #回合(Episode)設定初始化\n",
    "    \n",
    "    #開始進行模擬\n",
    "    \n",
    "    #評估結果\n",
    "    \n",
    "    #印出結果"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
